{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a45d60fa",
   "metadata": {},
   "source": [
    "# Machine Learning Notebook for bike/parking space predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068085ea",
   "metadata": {},
   "source": [
    "## Section 0: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d14f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833e674e",
   "metadata": {},
   "source": [
    "## Section 1: Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02d2877",
   "metadata": {},
   "source": [
    "### Section 1.1: Create a function to create to the SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb65e35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_database():\n",
    "    \"\"\"Function for connecting to the SQL database\"\"\"\n",
    "\n",
    "    # Create variables to store cretentials\n",
    "    USER = \"admin\"\n",
    "    DB = \"dbikes\"\n",
    "    PORT = \"3306\"\n",
    "    URL = \"database-1.ctesjcult8dm.eu-west-1.rds.amazonaws.com\"\n",
    "\n",
    "    # Read in password from text file\n",
    "    with open('../mysql_password.txt') as f:\n",
    "        PASSWORD = ''.join(f.readlines())\n",
    "        PASSWORD = str(PASSWORD).split()[0]\n",
    "\n",
    "    # Create engine using credentials\n",
    "    engine = create_engine(\n",
    "        \"mysql+mysqlconnector://{}:{}@{}:{}/{}\".format(USER, PASSWORD, URL, PORT, DB), echo=True)\n",
    "\n",
    "    # Create connection using engine and return connection\n",
    "    conn = engine.connect()\n",
    "    return conn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b463feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-24 09:07:08,917 INFO sqlalchemy.engine.Engine SHOW VARIABLES LIKE 'sql_mode'\n",
      "2022-03-24 09:07:08,919 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2022-03-24 09:07:08,953 INFO sqlalchemy.engine.Engine SHOW VARIABLES LIKE 'lower_case_table_names'\n",
      "2022-03-24 09:07:08,956 INFO sqlalchemy.engine.Engine [generated in 0.00878s] {}\n",
      "2022-03-24 09:07:08,984 INFO sqlalchemy.engine.Engine SELECT DATABASE()\n",
      "2022-03-24 09:07:08,986 INFO sqlalchemy.engine.Engine [raw sql] {}\n"
     ]
    }
   ],
   "source": [
    "engine = connect_to_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1987d9d",
   "metadata": {},
   "source": [
    "### Section 1.2: Read in real time bike/parking space availability data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "260097e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-24 09:07:09,107 INFO sqlalchemy.engine.Engine SELECT * FROM dbikes.availability\n",
      "2022-03-24 09:07:09,109 INFO sqlalchemy.engine.Engine [raw sql] {}\n"
     ]
    }
   ],
   "source": [
    "availability_df = pd.read_sql_query(\"SELECT * FROM dbikes.availability\", engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa41cf",
   "metadata": {},
   "source": [
    "### Section 1.3: Remove Duplicate values from real time availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92062119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "availability_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bfcec6",
   "metadata": {},
   "source": [
    "### Section 1.4: Read in weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2485768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-24 09:07:37,438 INFO sqlalchemy.engine.Engine SELECT dt, temperature, main FROM dbikes.real_time_weather\n",
      "2022-03-24 09:07:37,439 INFO sqlalchemy.engine.Engine [raw sql] {}\n"
     ]
    }
   ],
   "source": [
    "weather_df = pd.read_sql_query(\"SELECT dt, temperature, main FROM dbikes.real_time_weather\", engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f84e87c",
   "metadata": {},
   "source": [
    "### Section 1.5: Remove duplicate values from weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51e309b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicates\n",
    "weather_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ab350a",
   "metadata": {},
   "source": [
    "### Section 1.6: Rename last update column in availability dataframe to dt to help with the merging of the availability and weather dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3027bf73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number', 'available_bikes', 'available_stands', 'dt'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Changes the name of the column\n",
    "availability_df.rename(columns={\"last_update\": \"dt\"}, inplace=True)\n",
    "availability_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcd0254",
   "metadata": {},
   "source": [
    "### Section 1.7: Change the type of the dt variable to an np.int64 type for merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c92508ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "availability_df[\"dt\"] = availability_df[\"dt\"].astype(np.int64)\n",
    "weather_df[\"dt\"]= weather_df[\"dt\"].astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c009e62",
   "metadata": {},
   "source": [
    "### Section 1.8: Sort the dt columns for merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6784b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "availability_df.sort_values(by=\"dt\", inplace=True)\n",
    "weather_df.sort_values(by=\"dt\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cddd78",
   "metadata": {},
   "source": [
    "### Section 1.9: Convert seconds to milliseconds in dt column in availability so that it is comparable with the corresponding weather column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c600cc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts seconds to miliseconds\n",
    "availability_df[\"dt\"] = availability_df[\"dt\"] // 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f109117",
   "metadata": {},
   "source": [
    "### Section 1.10: Merge weather and availability dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2f8a866",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.merge_asof(availability_df, weather_df, on=\"dt\", direction=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac966f7",
   "metadata": {},
   "source": [
    "### Section 1.11: Convert temperature from Kelvin to Celcius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb53ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"temperature\"] = df[\"temperature\"] - 273.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57205a4b",
   "metadata": {},
   "source": [
    "### Section 1.12: Transform the dt column to get hour of the day and day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de0df62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"dt\"] = pd.to_datetime(df[\"dt\"], unit=\"s\")\n",
    "df[\"day_of_week\"] = df[\"dt\"].dt.day_name()\n",
    "df[\"hour\"] = df[\"dt\"].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18e06b8",
   "metadata": {},
   "source": [
    "### Section 1.13: Convert categorical variables to \"category\" data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c061867",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"main\"] = df[\"main\"].astype(\"category\")\n",
    "df[\"day_of_week\"] = df[\"day_of_week\"].astype(\"category\")\n",
    "df[\"hour\"] = df[\"hour\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f28d3cc",
   "metadata": {},
   "source": [
    "### Section 1.14: Get a list of station numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a06fc533",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_numbers = list(df[\"number\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ac5b14",
   "metadata": {},
   "source": [
    "### Section 1.15: Reencode categorical variables using binary encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2945d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_fields = [\"main\", \"hour\", \"day_of_week\"]\n",
    "for each in dummy_fields:\n",
    "    dummies = pd.get_dummies(df[each], prefix=each, drop_first = False)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "df = df.drop(dummy_fields, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ce6a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_column_names = list(df.columns)[4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7ea1d2",
   "metadata": {},
   "source": [
    "## Section 2: Model creation/evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8250be",
   "metadata": {},
   "source": [
    "### Section 2.1: Comparison of different ML models on a sample of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fe034d",
   "metadata": {},
   "source": [
    "We decided to compare a linear and logistic regression model on 20 of our bike stations, to try to ascertain if one model tends to outperform the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0b0f05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n",
      "55\n",
      "80\n",
      "32\n",
      "99\n",
      "115\n",
      "9\n",
      "18\n",
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\envs\\comp30830\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "62\n",
      "117\n",
      "42\n",
      "12\n",
      "82\n",
      "107\n",
      "28\n",
      "65\n",
      "40\n",
      "95\n",
      "{86: 64.74978649766668, 55: 18.20268286040057, 80: 57.741650911648414, 32: 39.881743838544736, 99: 18.978742062430353, 115: 32.925932491296614, 9: 32.726720392810336, 18: 32.266173314113246, 39: 19.814176111451168, 13: 27.807582091478118, 62: 29.6997877379184, 117: 43.92040831670165, 42: 33.12999781004087, 12: 19.919616724234004, 82: 21.960619635947907, 107: 50.695613446075065, 28: 34.4402953160158, 65: 69.23921796075479, 40: 33.30803209931803, 95: 73.28148788482353}\n",
      "{86: 88.03798100949525, 55: 26.94009216589862, 80: 96.47985537190083, 32: 63.51328553353016, 99: 24.489951113525258, 115: 48.79770444763271, 9: 54.747770246164826, 18: 41.220479302832246, 39: 28.724420190995907, 13: 40.61331038439472, 62: 44.853240492769146, 117: 64.52163742690058, 42: 50.021872265966756, 12: 33.89886425094646, 82: 37.86682107701216, 107: 81.44715025906736, 28: 49.91372351160444, 65: 123.2880658436214, 40: 60.372191011235955, 95: 116.98347521281923}\n"
     ]
    }
   ],
   "source": [
    "linear_regression = {}\n",
    "logistic_regression = {}\n",
    "linear_accuracy = {}\n",
    "logistic_accuracy = {}\n",
    "\n",
    "for station in station_numbers[:20]:\n",
    "    # Prepare the training and test data for both linear and logistic regression\n",
    "    station_df = df[df[\"number\"] == station]\n",
    "    X = station_df[x_column_names]\n",
    "    y = station_df[\"available_bikes\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    # Fit a logistic regression model\n",
    "    logistic_regression[station] = LogisticRegression( solver='lbfgs', max_iter=1500)\n",
    "    logistic_regression[station].fit(X_train, y_train)\n",
    "    y_pred_logistic = logistic_regression[station].predict(X_test)\n",
    "    logistic_accuracy[station] = mean_squared_error(y_test, y_pred_logistic)\n",
    "\n",
    "    # Fit a linear regression model\n",
    "    linear_regression[station] = LinearRegression()\n",
    "    linear_regression[station].fit(X_train, y_train)\n",
    "    y_pred_linear = linear_regression[station].predict(X_test)\n",
    "    linear_accuracy[station] = mean_squared_error(y_test, y_pred_linear)\n",
    "    \n",
    "    # file_name = \"station_\" + str(station) + \"_bike_model.pkl\"\n",
    "    # with open(file_name, 'wb') as handle:\n",
    "    #     pickle.dump(model, handle, pickle.HIGHEST_PROTOCOL)\n",
    "    print(station)\n",
    "\n",
    "print(linear_accuracy)\n",
    "print(logistic_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9173c0b0",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523a57d0",
   "metadata": {},
   "source": [
    "We see that linear regression tends to outperform logistic regression. Therefore, we have selected linear regression as our optimal model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da4a3dc",
   "metadata": {},
   "source": [
    "### Section 2.2: Implementation of linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "321bf383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16562335195596833\n",
      "86\n",
      "0.3468532672018232\n",
      "55\n",
      "0.2851236714758697\n",
      "80\n",
      "0.3961294730276673\n",
      "32\n",
      "0.5015255312464701\n",
      "99\n",
      "0.5716900044478127\n",
      "115\n",
      "0.34137670318309377\n",
      "9\n",
      "0.22246940657948777\n",
      "18\n",
      "0.19200485103780718\n",
      "39\n",
      "0.31464845780196116\n",
      "13\n",
      "0.44687807819119485\n",
      "62\n",
      "0.248199576523905\n",
      "117\n",
      "0.33244371277814166\n",
      "42\n",
      "0.16058545703704263\n",
      "12\n",
      "0.3071509749406345\n",
      "82\n",
      "0.25591982239597666\n",
      "107\n",
      "0.1590579094439779\n",
      "28\n",
      "0.08274604171717814\n",
      "65\n",
      "0.13514889294822496\n",
      "40\n",
      "0.2035491305867403\n",
      "95\n",
      "0.10459712400954346\n",
      "76\n",
      "0.29280923215884014\n",
      "47\n",
      "0.6186539556494146\n",
      "114\n",
      "0.19535050679774857\n",
      "15\n",
      "0.0486972635523053\n",
      "75\n",
      "0.20886682056987627\n",
      "24\n",
      "0.12996773025005226\n",
      "116\n",
      "0.3033391160893142\n",
      "25\n",
      "0.23668118083965695\n",
      "26\n",
      "0.0648301808652183\n",
      "16\n",
      "0.1269035166176996\n",
      "102\n",
      "0.14719984306431233\n",
      "59\n",
      "0.14017807182828856\n",
      "57\n",
      "0.5591311248496381\n",
      "112\n",
      "0.12328450805951141\n",
      "64\n",
      "0.3441287113344287\n",
      "3\n",
      "0.10459844810373387\n",
      "106\n",
      "0.3584415310301039\n",
      "109\n",
      "0.29951559519218873\n",
      "101\n",
      "0.3300278865219749\n",
      "21\n",
      "0.5466220426474904\n",
      "11\n",
      "0.427883502596221\n",
      "60\n",
      "0.11187300890134733\n",
      "58\n",
      "0.25080766515030695\n",
      "93\n",
      "0.30906560017905316\n",
      "63\n",
      "0.3048510039086627\n",
      "5\n",
      "0.2916902633026156\n",
      "111\n",
      "0.16259507035836318\n",
      "2\n",
      "0.2913286415082603\n",
      "87\n",
      "0.36349145976273156\n",
      "17\n",
      "0.5098700237554885\n",
      "27\n",
      "0.3793089617886991\n",
      "44\n",
      "0.35155889848273814\n",
      "91\n",
      "0.40257482012917734\n",
      "73\n",
      "0.349546009914697\n",
      "103\n",
      "0.34604442928316304\n",
      "51\n",
      "0.3421267645651468\n",
      "37\n",
      "0.31256509497747675\n",
      "7\n",
      "0.10174847891411665\n",
      "110\n",
      "0.2953323571004035\n",
      "97\n",
      "0.12657278826372864\n",
      "61\n",
      "0.3428562252524051\n",
      "89\n",
      "0.12368749260908596\n",
      "69\n",
      "0.10256890416528164\n",
      "38\n",
      "0.23135120580517599\n",
      "85\n",
      "0.30322021900432883\n",
      "52\n",
      "0.15251687190988583\n",
      "72\n",
      "0.08862463121439124\n",
      "104\n",
      "0.24765018131968575\n",
      "108\n",
      "0.2828318317971079\n",
      "98\n",
      "0.20531291776341265\n",
      "84\n",
      "0.1667456155248106\n",
      "78\n",
      "0.09422664479019416\n",
      "31\n",
      "0.3039074748183308\n",
      "68\n",
      "0.2744347159255094\n",
      "66\n",
      "0.18404802400846287\n",
      "94\n",
      "0.5184656162168604\n",
      "45\n",
      "0.4016726241061359\n",
      "36\n",
      "0.20535674739827414\n",
      "41\n",
      "0.23368279541639303\n",
      "50\n",
      "0.3919958823315183\n",
      "43\n",
      "0.5024424954653129\n",
      "71\n",
      "0.3286139126594374\n",
      "48\n",
      "0.24039431910235232\n",
      "105\n",
      "0.5150547545642209\n",
      "19\n",
      "0.17072343581397154\n",
      "96\n",
      "0.3231399007019323\n",
      "34\n",
      "0.22815234157812214\n",
      "30\n",
      "0.2925259709451845\n",
      "6\n",
      "0.20665012811038075\n",
      "22\n",
      "0.5149984466606201\n",
      "100\n",
      "0.17908355325271208\n",
      "10\n",
      "0.1958093056987783\n",
      "54\n",
      "0.5659653476247941\n",
      "67\n",
      "0.26078023703778874\n",
      "83\n",
      "0.10501077938176717\n",
      "23\n",
      "0.2869517463936889\n",
      "4\n",
      "0.33247464165270313\n",
      "8\n",
      "0.4846844741444024\n",
      "90\n",
      "0.2617388886998929\n",
      "88\n",
      "0.27166252568545224\n",
      "113\n",
      "0.15243729834884745\n",
      "77\n",
      "0.3114215263978207\n",
      "74\n",
      "0.2934134585406827\n",
      "29\n",
      "0.2999949780980643\n",
      "56\n",
      "0.10850639857587185\n",
      "79\n",
      "0.3014181715760553\n",
      "53\n",
      "0.2707950943134918\n",
      "92\n",
      "0.37754206316050354\n",
      "49\n",
      "0.19056836663158994\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "bike_availability = {}\n",
    "station_availability = {}\n",
    "\n",
    "for station in station_numbers:\n",
    "    # Prepare the training and test data for both linear and logistic regression\n",
    "    station_df = df[df[\"number\"] == station]\n",
    "    X = station_df[x_column_names]\n",
    "    y_bikes = station_df[\"available_bikes\"]\n",
    "    y_stations = station_df[\"available_stands\"]\n",
    "    X_train_bikes, X_test_bikes, y_train_bikes, y_test_bikes = train_test_split(X, y_bikes, test_size=0.3)\n",
    "    X_train_stations, X_test_stations, y_train_stations, y_test_stations = train_test_split(X, y_stations, test_size=0.3)\n",
    "\n",
    "    # Fit a linear regression model for bike availability\n",
    "    bike_availability[station] = LinearRegression()\n",
    "    bike_availability[station].fit(X_train_bikes, y_train_bikes)\n",
    "\n",
    "    # Fit a linear regression model for bike availability\n",
    "    station_availability[station] = LinearRegression()\n",
    "    station_availability[station].fit(X_train_stations, y_train_stations)\n",
    "    \n",
    "    file_name_bikes = \"station_\" + str(station) + \"_bike_model.pkl\"\n",
    "    with open(file_name_bikes, 'wb') as handle:\n",
    "        pickle.dump(bike_availability[station], handle, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    file_name_stations = \"station_\" + str(station) + \"_station_model.pkl\"\n",
    "    with open(file_name_stations, 'wb') as handle:\n",
    "        pickle.dump(station_availability, handle, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print(station)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0d4e5d",
   "metadata": {},
   "source": [
    "## Section 3: Testing our final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8fcecaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>main_Clear</th>\n",
       "      <th>main_Clouds</th>\n",
       "      <th>main_Drizzle</th>\n",
       "      <th>main_Mist</th>\n",
       "      <th>main_Rain</th>\n",
       "      <th>main_Snow</th>\n",
       "      <th>hour_0</th>\n",
       "      <th>hour_1</th>\n",
       "      <th>hour_2</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "      <th>hour_23</th>\n",
       "      <th>day_of_week_Friday</th>\n",
       "      <th>day_of_week_Monday</th>\n",
       "      <th>day_of_week_Saturday</th>\n",
       "      <th>day_of_week_Sunday</th>\n",
       "      <th>day_of_week_Thursday</th>\n",
       "      <th>day_of_week_Tuesday</th>\n",
       "      <th>day_of_week_Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>444937</th>\n",
       "      <td>3.85</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        temperature  main_Clear  main_Clouds  main_Drizzle  main_Mist  \\\n",
       "444937         3.85           0            1             0          0   \n",
       "\n",
       "        main_Rain  main_Snow  hour_0  hour_1  hour_2  ...  hour_21  hour_22  \\\n",
       "444937          0          0       0       0       0  ...        0        0   \n",
       "\n",
       "        hour_23  day_of_week_Friday  day_of_week_Monday  day_of_week_Saturday  \\\n",
       "444937        0                   0                   0                     0   \n",
       "\n",
       "        day_of_week_Sunday  day_of_week_Thursday  day_of_week_Tuesday  \\\n",
       "444937                   0                     0                    0   \n",
       "\n",
       "        day_of_week_Wednesday  \n",
       "444937                      1  \n",
       "\n",
       "[1 rows x 38 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_x_data = X_test.head(1)\n",
    "sample_x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0cfd56c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('station_32_bike_model.pkl', 'rb') as handle:\n",
    "    station_32_model = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46c7ead1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.86816406]\n"
     ]
    }
   ],
   "source": [
    "print(station_32_model.predict(sample_x_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
